---
layout:     post
title: 	    "Lyttende tv afslører fremtiden for talegenkendelse"
post_author:	    Rasmus Ekberg Villumsen
post_date:	    Fri, 20 Feb 2015 05:29:40 +0000
post_site:	    www.version2.dk 
post_link:	    http://www.version2.dk/artikel/lyttende-tv-afsloerer-fremtiden-talegenkendelse-80659?utm_medium=feed&utm_source=version2.dk&utm_campaign=it_nyheder
---
<html><body><div><section class="body"><p>It-ordførerne på Christiansborg, Forbrugerrådet Tænk og almindelige forbrugere slog for nylig løs på et nyt smart-tv fra Samsung.</p>

<p>Det nye tv optager lydene omkring sig og sender dem via nettet til et firma, der genkender talekommandoer og sørger for, at tv’et bl.a. kan skifte kanal, uden at du behøver løfte en finger.</p>

<p>Kritikken bundede i en frygt for overvågning i hjemmet, men midt i den ophedede diskussion druknede et kig på det teknologiske fremskridt. Netop tv’ets kobling til nettet er nemlig det trick, der får talegenkendelse til at sprede sig i disse år.</p>

<p>I stedet for at et apparat – i dette tilfælde dit tv – selv prøver at matche dine talte kommandoer med et begrænset antal forprogrammerede kommandoer på en lagerenhed i tv’et, kan det ved opkobling til nettet trække på et stadigt stigende antal lagrede kommandoer i skyen.</p>

<p>Jens Kjærum er direktør i det danske talegenkendelsesfirma Dictus, og han forklarer gevinsten ved at anvende cloud-teknologi til talegenkendelse på denne måde:</p>

<p>»Med cloudteknologi har man forbedret lingware, altså talegenkenderens sprogressourcer (forståelsen for sprogets ordforråd og grammatiske opbygning, red.). Netop sprogressourcerne har haltet bagefter, fordi det har krævet rigtig meget manpower og mange ressourcer at udvikle – bare til engelsk. Og det er næsten helt umuligt at bruge de samme ressourcer på mindre sprog som f.eks. dansk. Men når man har det ude i clouden og har gjort det let tilgængeligt på mobiltelefoner, så får du pludselig noget big data, som gør, at man med nogle algoritmer kan udnytte det, som man før var nødt til at investere mange ressourcer og meget manpower i.«</p>

<p><figure class="plugin right zoomable"><img data-original-image="http://www.version2.dk/sites/v2/files/2015.02.20-talegenkendelse-hoej.png" src="http://www.version2.dk/sites/v2/files/styles/medium/public/2015.02.20-talegenkendelse-hoej.png?itok=3IDkuCSo" alt=""/><figcaption><cite>Foto: Nanna Skytte</cite></figcaption></figure>På den baggrund mener Jens Kjærum, at talegenkendelse er midt i en revolution:</p>

<p>»For et par år siden ville det være fuldstændig sci-fi, at man kunne tale til sit fjernsyn og sige: ‘Vis mig en film med Harrison Ford’. Men teknologien er blevet så god, at det faktisk er muligt at gøre det – vel at mærke uden, at talegenkendelsesprogrammet laver for mange fejl,« siger han.</p>

<p>Samsung benytter sig af det amerikanske firma Nuance, der også leverer talegenkendelse til biler, sundhedssektoren og flere andre producenter af smart-tv. Også Apples Siri, Google Now og Microsofts Cortana anvender cloud-teknologi til talegenkendelse.</p>

<h2>Talegenkendelse kræver kræfter</h2>

<p>Talegenkendelse bliver normalt opdelt i tre faser – akustisk modellering, udtalemodellering og sprogmodellering (se boksen). Og det er altså sprogmodelleringen, der har fået et boost af den store dataindsamling, der kan foregå via cloudteknologi.</p>

<p>Sprogmodelleringen i talegenkendelsesprogrammer virker ved, at programmet analyserer nogle tekststrenge og finder det, som der med størst sandsynlighed er blevet sagt.</p>

<p>Andreas Søeborg Kirkedal, ekstern ph.d. ved Mirsk Digital Aps, uddyber:</p>

<p>»Programmet står med en masse tekststrenge, og skal så finde ud af, hvad der er blevet sagt. Det kigger på det ord, der står til venstre – altså før. Det ord, der står foran, er nemlig ret godt til at vise, hvad der mest sandsynligt skal komme efter. Når man så kigger på konteksten, kan programmet fortælle, hvilket ord der med størst sandsynlighed passer bedst ind.«</p>

<p>Andreas Søeborg Kirkedal forklarer, at online-talegenkendelsen er smart, når vi benytter os af f.eks. mobilen, da regnekraften, der skal til at for at foretage talegenkendelsen, sker på en ekstern server.</p>

<p>»Hvis man gør det online, tager den lydbidderne og sender dem til en server. Serveren knuser så tal­lene for dig, og derfor skal din enhed kun stå for at sende og modtage information, hvilket ikke kræver så meget.«</p>

<p>Han forklarer yderligere, at hvis offline-stemmegenkendelse skulle være lige så omfattende som online, ville det tappe ens mobil for strøm på ingen tid.</p>

<p>»Det vil dræne batteriet alt for hurtigt. Derfor sætter man historikken ned, altså hvor mange ord den skal kigge tilbage, og man kan også begrænse, hvor mange ord den lokale enhed kan forstå, så det ikke kræver for meget,« siger han.</p>

<p><em>Denne artikel stammer fra den trykte udgave af Ingeniøren, som udkommer i fredag d. 20 februar 2015.</em></p>
  </section></div></body></html>
